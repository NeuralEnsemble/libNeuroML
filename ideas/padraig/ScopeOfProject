Some ideas on the scope of the project


NeuroML:

NeuroML will provide the core object model for describing neuronal morphologies, ion channels, synapses and 
3D network structure.
Any dynamical components (channels, synapses, abstratc cell models) will have a definition "behind the scenes" in LEMS.
However, all NeuroML will specify is that "element segment will contain element distal with attributes x, y, z, 
diameter..." or "element izhikevichCell will have attributes a, b, c..."


Serialisations:

A) The XML serialisation will be the "natural" serialistaion and will be a pretty faithful reflection of the object 
model. This will be specified by the XML Schema definition (XSD file). Note LEMS definition and XSD file are kept 
manually in line. 
B) There should be a standardised (and validatable) HDF5 serialisation. This can use the overall structure of the 
NeuroML object model, but use obtimised representaions of 1) neuronal morphologies, 2) cell locations and 3) synaptic 
connectivity. This can be based on Stephan's examples for NeuroHDF
C) Other serialisation formats could be envisioned, e.g. YAML. That format would most likely have a one to one mapping 
to the XML format. Other binary formats (e.g. Binary XML) may be unnecessary, since HDF5 should cover most of our needs


APIs for accessing NeuroML files:

APIs in any given language (e.g. Java, Python) should be independent of the serialisation format, and be based on the 
NeuroML object model.


Backends
 
A backend is the language specific implementation in which the structure of the cells, network, etc. is stored when the
model is loaded in from XML/HDF5. Scenarios for this can include:

A) Language specific object model generated from NeuroML schema, e.g. Java or Python class hierarchy for Cell, Segment, 
Network, etc.
B) Optimised version of above with certain objects substituted for more optimal representations of data (e.g. a numpy 
array for 3D points) 
C) Simulator specific backend, i.e. when neuroml.addCell(...) or cell.addSegment() are called, equivalent entities 
in the simulator are created.

Scenario A) above already has an initial implementation in Python (see 
https://github.com/NeuralEnsemble/libNeuroML/tree/master/ideas/padraig/generatedFromV2Schema).
Scenario B) would fulfil most people's requirements for a standalone Python API to read/write large data sets of 
cell/network data
Scenario C) could be implemented by extending PyNN for multicompartmental simulators, and by hooking commands for 
building networks in libNeuroML (e.g. addCell(), addPopulation, createSegment()) to existing or new PyNN commands,
and similarly parsing the simulator's internally instantiated network with PyNN commands when the network needs to
be saved to XML/HDF5.



Some ideas on the scope of the project


* NeuroML

NeuroML will provide the core object model for describing neuronal morphologies, ion channels, synapses and 
3D network structure.
Any dynamical components (channels, synapses, abstratc cell models) will have a definition "behind the scenes" in LEMS.
However, all NeuroML will specify is that "element segment will contain element distal with attributes x, y, z, 
diameter..." or "element izhikevichCell will have attributes a, b, c..."


* Serialisations

A) The XML serialisation will be the "natural" serialisation and will be a pretty faithful reflection of the NeuroML
object model. The format of the XML will be specified by the XML Schema definition (XSD file). Note LEMS definitions 
and this XSD file are kept manually in line. 
B) There should be a standardised (and verifiable) HDF5 serialisation. This can be based on the overall structure of the 
NeuroML object model, but use optimised internal representaions of 1) neuronal morphologies, 2) cell locations and 3) 
synaptic connectivity. This can be based on Stephan's examples for representing morphs & networks in NeuroHDF
C) Other serialisation formats could be envisioned, e.g. YAML. That format would most likely have a one to one mapping 
to the XML format. Other binary formats (e.g. Binary XML) may be unnecessary, since HDF5 should cover most of our needs


* APIs for accessing NeuroML files (libNeuroML instances)

APIs in any given language (e.g. Java, Python) should be independent of the serialisation format, and be based on the 
NeuroML object model.
Core read/write methods will be here, e.g. readNeuroML(xmlOrHdfFormat), getCells(), cell.getSegments(), getPopulations(), 
getProjections(), cell.addSegment(), cell.getSegmentsInGroup(grp), addPopulation(), saveAsXML(), saveAsHDF5(), etc.
Additional helper methods could be envisioned across the implementations, e.g. cell.retrieveCoordinates(), etc. 

The naming convention (camelCase?) of methods will be a thorny issue, but I'd argue that it should be uniform across 
language implementations, as it is in libSBML


* Backends
 
A backend consists of a specific implementation which stores structure of the cells, network, etc. when the
model is loaded in from XML/HDF5. Scenarios for this can include:

A) A language specific object model generated from the NeuroML schema, e.g. Java or Python class hierarchy for Cell, Segment, 
Network, etc. is used to store the data
B) Optimised version of above with certain objects substituted for more optimal representations of data (e.g. a numpy 
array for 3D points) 
C) Simulator specific backend, i.e. when addCell(...) or cell.addSegment() are called, equivalent entities 
in the native simulator are created. Similarly when saveAsXML() is called in the API the native object tree is parsed for 
this information.

Scenario A) above already has an initial implementation in Python (see 
https://github.com/NeuralEnsemble/libNeuroML/tree/master/ideas/padraig/generatedFromV2Schema).
Scenario B) would fulfil most people's requirements for a standalone Python API to read/write large data sets of 
cell/network data, and could be build from A
Scenario C) could be implemented in Python by extending PyNN for multicompartmental simulators, and by hooking 
commands for building networks in libNeuroML (e.g. addCell(), addPopulation, createSegment()) to existing or new 
PyNN commands, and similarly parsing the simulator's internally instantiated network with PyNN commands when the 
network needs to be saved to XML/HDF5. This would facilitate running/saving/plotting models on PyNN simulators.


* Extensions

The core libNeuroML API should be kept to the minimal set of commands for reading/writing/parsing the object tree.
Extension packages can be built on this (and PyNN) which use this functionality with specific workflows in mind, e.g.
building small etworks of multicomp neurons with MorphForge, optimising 

